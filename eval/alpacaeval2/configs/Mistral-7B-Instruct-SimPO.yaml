Mistral-7B-Instruct-SimPO:
  completions_kwargs:
    batch_size: 900
    max_new_tokens: 2048
    model_kwargs:
      torch_dtype: bfloat16
    model_name: princeton-nlp/Mistral-7B-Instruct-SimPO
    temperature: 0.5
  fn_completions: vllm_local_completions
  pretty_name: snorkel-beta-3-7b-dpo-full-lr-2e-7-bs-32-len-norm
  prompt_template: templates/mistral_instruct.txt